{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Mask R-CNN for Disease Detection and Segmentation"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\admin\\desktop\\dissertation\\mask-rcnn-tf2-win\\.venv\\lib\\site-packages)\n","\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Package                       Version\n","----------------------------- --------------\n","absl-py                       1.4.0\n","alabaster                     0.7.13\n","anyio                         4.1.0\n","argon2-cffi                   23.1.0\n","argon2-cffi-bindings          21.2.0\n","array-record                  0.4.0\n","arrow                         1.3.0\n","asttokens                     2.4.1\n","astunparse                    1.6.3\n","async-lru                     1.0.3\n","atomicwrites                  1.4.1\n","attrs                         23.2.0\n","Babel                         2.14.0\n","backcall                      0.2.0\n","beautifulsoup4                4.12.3\n","black                         24.4.2\n","bleach                        6.1.0\n","cachetools                    4.2.4\n","certifi                       2024.2.2\n","cffi                          1.16.0\n","charset-normalizer            3.3.2\n","click                         8.1.7\n","colorama                      0.4.6\n","comm                          0.2.2\n","contourpy                     1.1.1\n","curio                         1.6\n","cycler                        0.12.1\n","Cython                        3.0.10\n","debugpy                       1.8.1\n","decorator                     5.1.1\n","defusedxml                    0.7.1\n","dm-tree                       0.1.8\n","docrepr                       0.2.0\n","docutils                      0.20.1\n","entrypoints                   0.4\n","etils                         1.3.0\n","exceptiongroup                1.2.1\n","executing                     2.0.1\n","fastjsonschema                2.19.1\n","flatbuffers                   24.3.25\n","fonttools                     4.51.0\n","fqdn                          1.5.1\n","gast                          0.3.3\n","google-auth                   2.34.0\n","google-auth-oauthlib          1.0.0\n","google-pasta                  0.2.0\n","googleapis-common-protos      1.63.2\n","grpcio                        1.66.0\n","h11                           0.14.0\n","h5py                          2.10.0\n","httpcore                      1.0.5\n","httpx                         0.27.0\n","idna                          3.7\n","imageio                       2.34.1\n","imagesize                     1.4.1\n","imgaug                        0.4.0\n","importlib_metadata            7.1.0\n","importlib_resources           6.4.0\n","iniconfig                     2.0.0\n","ipykernel                     6.29.4\n","ipyparallel                   8.8.0\n","ipython                       7.34.0\n","ipywidgets                    8.1.2\n","isoduration                   20.11.0\n","jedi                          0.19.1\n","Jinja2                        3.1.3\n","joblib                        1.4.2\n","json5                         0.9.25\n","jsonpointer                   2.4\n","jsonschema                    4.21.1\n","jsonschema-specifications     2023.12.1\n","jupyter_client                8.6.1\n","jupyter_core                  5.7.2\n","jupyter-events                0.10.0\n","jupyter-lsp                   2.2.5\n","jupyter_server                2.14.0\n","jupyter_server_terminals      0.5.3\n","jupyterlab                    4.1.8\n","jupyterlab_pygments           0.3.0\n","jupyterlab_server             2.27.1\n","jupyterlab_widgets            3.0.10\n","Keras                         2.3.1\n","Keras-Applications            1.0.8\n","keras-core                    0.1.5\n","keras-cv                      0.6.4\n","Keras-Preprocessing           1.1.2\n","kiwisolver                    1.4.5\n","libclang                      18.1.1\n","Markdown                      3.6\n","markdown-it-py                3.0.0\n","MarkupSafe                    2.1.5\n","mask-rcnn-tf2                 1.0\n","matplotlib                    3.5.3\n","matplotlib-inline             0.1.7\n","mdurl                         0.1.2\n","mistune                       3.0.2\n","mypy-extensions               1.0.0\n","namex                         0.0.8\n","nbclient                      0.10.0\n","nbconvert                     7.16.3\n","nbformat                      5.10.4\n","nest-asyncio                  1.6.0\n","networkx                      3.1\n","nose                          1.3.7\n","notebook                      7.1.3\n","notebook_shim                 0.2.4\n","numpy                         1.18.5\n","oauthlib                      3.2.2\n","opencv-python                 4.9.0.80\n","opt-einsum                    3.3.0\n","outcome                       1.3.0.post0\n","overrides                     7.7.0\n","packaging                     24.0\n","pandas                        2.0.3\n","pandocfilters                 1.5.1\n","parso                         0.8.4\n","pathspec                      0.12.1\n","pickleshare                   0.7.5\n","pillow                        10.3.0\n","pip                           24.0\n","pkgutil_resolve_name          1.3.10\n","platformdirs                  4.2.1\n","pluggy                        1.5.0\n","prometheus_client             0.20.0\n","promise                       2.3\n","prompt-toolkit                3.0.43\n","protobuf                      3.20.0\n","psutil                        5.9.8\n","pure-eval                     0.2.2\n","py                            1.11.0\n","pyasn1                        0.6.0\n","pyasn1_modules                0.4.0\n","pycparser                     2.22\n","Pygments                      2.17.2\n","pyparsing                     3.1.2\n","pytest                        6.2.5\n","pytest-asyncio                0.20.3\n","python-dateutil               2.9.0.post0\n","python-json-logger            2.0.7\n","pytz                          2024.1\n","PyWavelets                    1.4.1\n","pywin32                       306\n","pywinpty                      2.0.13\n","PyYAML                        6.0.1\n","pyzmq                         26.0.2\n","qtconsole                     5.5.1\n","QtPy                          2.4.1\n","referencing                   0.35.0\n","regex                         2024.7.24\n","requests                      2.31.0\n","requests-oauthlib             2.0.0\n","rfc3339-validator             0.1.4\n","rfc3986-validator             0.1.1\n","rich                          13.7.1\n","rpds-py                       0.18.0\n","rsa                           4.9\n","scikit-image                  0.16.2\n","scikit-learn                  1.3.2\n","scipy                         1.4.1\n","Send2Trash                    1.8.3\n","setuptools                    56.0.0\n","shapely                       2.0.4\n","six                           1.15.0\n","sniffio                       1.3.1\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","soupsieve                     2.5\n","Sphinx                        7.1.2\n","sphinx-rtd-theme              2.0.0\n","sphinxcontrib-applehelp       1.0.4\n","sphinxcontrib-devhelp         1.0.2\n","sphinxcontrib-htmlhelp        2.0.1\n","sphinxcontrib-jquery          4.1\n","sphinxcontrib-jsmath          1.0.1\n","sphinxcontrib-qthelp          1.0.3\n","sphinxcontrib-serializinghtml 1.1.5\n","stack-data                    0.6.3\n","tensorboard                   2.13.0\n","tensorboard-data-server       0.7.2\n","tensorboard-plugin-wit        1.8.1\n","tensorflow                    2.3.4\n","tensorflow-datasets           4.9.2\n","tensorflow-estimator          2.3.0\n","tensorflow-intel              2.13.0\n","tensorflow-io-gcs-filesystem  0.31.0\n","tensorflow-metadata           1.14.0\n","termcolor                     1.1.0\n","terminado                     0.18.1\n","testpath                      0.6.0\n","threadpoolctl                 3.5.0\n","tinycss2                      1.3.0\n","toml                          0.10.2\n","tomli                         2.0.1\n","tornado                       6.4\n","tqdm                          4.66.2\n","traitlets                     5.14.3\n","trio                          0.25.0\n","types-python-dateutil         2.9.0.20240316\n","typing_extensions             4.5.0\n","tzdata                        2024.1\n","uri-template                  1.3.0\n","urllib3                       2.2.1\n","wcwidth                       0.2.13\n","webcolors                     1.13\n","webencodings                  0.5.1\n","websocket-client              1.8.0\n","Werkzeug                      3.0.2\n","wheel                         0.43.0\n","widgetsnbextension            4.0.10\n","wrapt                         1.12.1\n","zipp                          3.18.1\n"]}],"source":["import os\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","from numpy import zeros, asarray\n","\n","import mrcnn\n","import mrcnn.utils\n","import mrcnn.config\n","import mrcnn.model\n","import tensorflow as tf\n","\n","import time\n","from datetime import datetime\n","\n","!pip list"]},{"cell_type":"markdown","metadata":{},"source":["## Define the `DiseaseDataset` Class"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DiseaseDataset(mrcnn.utils.Dataset):\n","\n","    def load_dataset(self, dataset_dir, is_train=True):\n","        self.add_class(\"dataset\", 1, \"disease\")\n","        \n","        images_dir = os.path.join(dataset_dir, 'images')\n","        annotations_dir = os.path.join(dataset_dir, 'annots')\n","        \n","        all_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n","        all_ids = [os.path.splitext(fname)[0] for fname in all_files]\n","        all_ids = sorted(all_ids)  # Ensure consistent order\n","\n","        split_index = int(0.8 * len(all_ids))  # 80%-20% train-val split\n","        if is_train:\n","            ids = all_ids[:split_index]\n","        else:\n","            ids = all_ids[split_index:]\n","\n","        for image_id in ids:\n","            img_path = os.path.join(images_dir, image_id + '.jpg')\n","            ann_path = os.path.join(annotations_dir, image_id + '.xml')\n","\n","            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n","\n","    # Loads the binary masks for an image.\n","    def load_mask(self, image_id):\n","        info = self.image_info[image_id]\n","        path = info['annotation']\n","        boxes, w, h = self.extract_boxes(path)\n","        masks = zeros([h, w, len(boxes)], dtype='uint8')\n","\n","        class_ids = list()\n","        for i in range(len(boxes)):\n","            box = boxes[i]\n","            row_s, row_e = box[1], box[3]\n","            col_s, col_e = box[0], box[2]\n","            masks[row_s:row_e, col_s:col_e, i] = 1\n","            class_ids.append(self.class_names.index('disease'))\n","        return masks, asarray(class_ids, dtype='int32')\n","\n","    # A helper method to extract the bounding boxes from the annotation file\n","    def extract_boxes(self, filename):\n","        tree = ET.parse(filename)\n","\n","        root = tree.getroot()\n","\n","        boxes = list()\n","        for box in root.findall('.//bndbox'):\n","            xmin = int(box.find('xmin').text)\n","            ymin = int(box.find('ymin').text)\n","            xmax = int(box.find('xmax').text)\n","            ymax = int(box.find('ymax').text)\n","            coors = [xmin, ymin, xmax, ymax]\n","            boxes.append(coors)\n","\n","        width = int(root.find('.//size/width').text)\n","        height = int(root.find('.//size/height').text)\n","        return boxes, width, height"]},{"cell_type":"markdown","metadata":{},"source":["## Define the `DiseaseConfig` Class"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DiseaseConfig(mrcnn.config.Config):\n","    NAME = \"disease_cfg\"\n","\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    \n","    NUM_CLASSES = 2\n","\n","    # FOR TESTING\n","    STEPS_PER_EPOCH = 20\n","    #STEPS_PER_EPOCH = 588"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare the Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# dataset_root_path = os.path.join(os.getcwd(), 'data')\n","# for testing, using a smaller dataset.\n","dataset_root_path = os.path.join(os.getcwd(), 'data-20')\n","\n","# Train\n","train_dataset = DiseaseDataset()\n","train_dataset.load_dataset(dataset_dir=dataset_root_path, is_train=True)\n","train_dataset.prepare()\n","\n","# Validation\n","validation_dataset = DiseaseDataset()\n","validation_dataset.load_dataset(dataset_dir=dataset_root_path, is_train=False)\n","validation_dataset.prepare()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Define the Inference Configuration and Model Setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a new configuration for inference mode\n","class InferenceConfig(DiseaseConfig):\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","inference_config = InferenceConfig()"]},{"cell_type":"markdown","metadata":{},"source":["## Metrics per epoch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calculate_mean_iou(y_true, y_pred):\n","    # Ensure y_true and y_pred have the same shape\n","    if y_true.shape[-1] != y_pred.shape[-1]:\n","        # Compute IoU per predicted mask with all ground truth masks and pick the maximum\n","        iou_scores = []\n","        for i in range(y_pred.shape[-1]):\n","            pred_mask = y_pred[:, :, i]\n","            max_iou = 0\n","            for j in range(y_true.shape[-1]):\n","                true_mask = y_true[:, :, j]\n","                intersection = np.logical_and(pred_mask, true_mask)\n","                union = np.logical_or(pred_mask, true_mask)\n","                iou = np.sum(intersection) / np.sum(union)\n","                max_iou = max(max_iou, iou)\n","            iou_scores.append(max_iou)\n","        \n","        # Mean IoU across all predicted masks\n","        mean_iou_value = np.mean(iou_scores)\n","        return mean_iou_value\n","    else:\n","        # Direct IoU calculation if they match in number\n","        intersection = np.logical_and(y_true, y_pred)\n","        union = np.logical_or(y_true, y_pred)\n","        iou_score = np.sum(intersection) / np.sum(union)\n","        return iou_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MetricsCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, log_file='training_metrics.log'):\n","        super(MetricsCallback, self).__init__()\n","        self.log_file = log_file\n","        self.start_time = None\n","        self.best_mean_iou = 0.0  # Initialize best IoU to a low value\n","        self.best_checkpoint_path = 'best_model.h5'  # Path to save the best model\n","\n","        # Check if the log file exists; if not, create it and add headers\n","        if not os.path.exists(self.log_file):\n","            with open(self.log_file, 'w') as f:\n","                f.write(\"start_time,epoch,end_time,epoch_duration,mean_iou,mean_precision,mean_recall,mean_f1_score\\n\")\n","\n","    def on_train_begin(self, logs=None):\n","        # Record the training start time\n","        self.start_time = datetime.now()\n","        formatted_start_time = self.start_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n","        print(f\"Training started at: {formatted_start_time}\")\n","\n","        # Log the training start time to the file\n","        with open(self.log_file, 'a') as f:\n","            f.write(f\"{formatted_start_time},N/A,N/A,N/A,N/A,N/A,N/A,N/A\\n\")\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        print(f'\\nEpoch {epoch + 1} Metrics:')\n","\n","        # Record the end time of the epoch\n","        end_time = datetime.now()\n","        epoch_duration = (end_time - self.start_time).total_seconds()\n","        formatted_end_time = end_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n","        \n","        # Save weights after each epoch\n","        model_path = f'Disease_mask_rcnn_epoch_{epoch + 1}.h5'\n","        self.model.save_weights(model_path)\n","\n","        # Create inference model after saving weights\n","        inference_model = mrcnn.model.MaskRCNN(mode='inference', \n","                                               model_dir='./', \n","                                               config=inference_config)\n","\n","        inference_model.load_weights(model_path, by_name=True)\n","\n","        # Initialize lists to store metric results for this epoch\n","        val_iou = []\n","        precisions, recalls, f1_scores = [], [], []\n","        \n","        for image_id in validation_dataset.image_ids:\n","            image = validation_dataset.load_image(image_id)\n","            mask, _ = validation_dataset.load_mask(image_id)\n","            results = inference_model.detect([image], verbose=0)\n","            pred_mask = results[0]['masks']\n","            \n","            if pred_mask.shape[-1] > 0 and mask.shape[-1] > 0:\n","                # Compute IoU for each predicted mask with each true mask\n","                iou_matrix = np.zeros((pred_mask.shape[-1], mask.shape[-1]))\n","                for i in range(pred_mask.shape[-1]):\n","                    for j in range(mask.shape[-1]):\n","                        intersection = np.logical_and(pred_mask[:, :, i], mask[:, :, j])\n","                        union = np.logical_or(pred_mask[:, :, i], mask[:, :, j])\n","                        iou = np.sum(intersection) / np.sum(union)\n","                        iou_matrix[i, j] = iou\n","                \n","                # Match predicted masks to true masks based on IoU\n","                matches = np.argmax(iou_matrix, axis=1)  # Match each prediction to the best true mask\n","                \n","                for i, match in enumerate(matches):\n","                    max_iou = iou_matrix[i, match]\n","                    val_iou.append(max_iou)\n","                    \n","                    # Calculate precision and recall for the matched pair\n","                    pred = pred_mask[:, :, i]\n","                    true = mask[:, :, match]\n","                    intersection = np.logical_and(pred, true)\n","                    union = np.logical_or(pred, true)\n","                    \n","                    precision = np.sum(intersection) / np.sum(pred) if np.sum(pred) > 0 else 0\n","                    recall = np.sum(intersection) / np.sum(true) if np.sum(true) > 0 else 0\n","                    precisions.append(precision)\n","                    recalls.append(recall)\n","                    \n","                    # Calculate F1 score\n","                    if precision + recall > 0:\n","                        f1 = 2 * (precision * recall) / (precision + recall)\n","                    else:\n","                        f1 = 0\n","                    f1_scores.append(f1)\n","        \n","        # Compute mean metrics for the epoch\n","        mean_iou_value = np.mean(val_iou)\n","        mean_precision = np.mean(precisions)\n","        mean_recall = np.mean(recalls)\n","        mean_f1_score = np.mean(f1_scores)\n","\n","        # Log metrics\n","        logs['mean_iou'] = mean_iou_value\n","        logs['mean_precision'] = mean_precision\n","        logs['mean_recall'] = mean_recall\n","        logs['mean_f1_score'] = mean_f1_score\n","\n","        # Check if current mean IoU is better than the best recorded mean IoU\n","        if mean_iou_value > self.best_mean_iou:\n","            print(f\"Mean IoU improved from {self.best_mean_iou:.4f} to {mean_iou_value:.4f}. Saving model checkpoint.\")\n","            self.best_mean_iou = mean_iou_value\n","            self.model.save_weights(self.best_checkpoint_path)\n","\n","        # Save metrics to a log file\n","        with open(self.log_file, 'a') as f:\n","            f.write(f\"{self.start_time.strftime('%Y-%m-%d %H:%M:%S')},{epoch + 1},{formatted_end_time},{epoch_duration:.2f},{mean_iou_value:.4f},{mean_precision:.4f},{mean_recall:.4f},{mean_f1_score:.4f}\\n\")\n","        \n","        # Reset start time for the next epoch\n","        self.start_time = datetime.now()\n","\n","        # Print other metrics that Keras already computes\n","        for metric_name, metric_value in logs.items():\n","            print(f'{metric_name}: {metric_value:.4f}')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Configure and Train the Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No checkpoint found. Starting training from scratch.\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: ./disease_cfg20240824T1530\\mask_rcnn_disease_cfg_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Admin\\Desktop\\dissertation\\Mask-RCNN-TF2-Win\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... cannot pickle '_thread.RLock' object\n","Training started at: 2024-08-24 15:30:29\n","Epoch 1/2\n","20/20 [==============================] - 1255s 63s/step - loss: 4.8663 - val_loss: 2.1485\n","\n","Epoch 1 Metrics:\n","mean_iou: 0.2861\n","mean_precision: 0.7312\n","mean_recall: 0.3908\n","mean_f1_score: 0.3761\n","Mean IoU improved from 0.0000 to 0.2861. Saving model checkpoint.\n","val_loss: 2.1485\n","loss: 4.8663\n","mean_iou: 0.2861\n","mean_precision: 0.7312\n","mean_recall: 0.3908\n","mean_f1_score: 0.3761\n","Epoch 2/2\n"," 1/20 [>.............................] - ETA: 11:40 - loss: 2.0401"]}],"source":["# Model Configuration\n","disease_config = DiseaseConfig()\n","\n","# Build the Mask R-CNN Model Architecture\n","model = mrcnn.model.MaskRCNN(mode='training', \n","                             model_dir='./', \n","                             config=disease_config)\n","\n","model.load_weights(filepath='mask_rcnn_coco.h5', \n","                   by_name=True, \n","                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n","\n","# Path to save model checkpoints\n","checkpoint_dir = './'  # Adjust the path if needed\n","checkpoint_path = None\n","initial_epoch = 0\n","\n","# Find the latest checkpoint file\n","for file in os.listdir(checkpoint_dir):\n","    if file.startswith('Disease_mask_rcnn_epoch_') and file.endswith('.h5'):\n","        epoch_num = int(file.split('_')[-1].split('.')[0])\n","        if epoch_num > initial_epoch:\n","            initial_epoch = epoch_num\n","            checkpoint_path = os.path.join(checkpoint_dir, file)\n","\n","# Load weights from the latest checkpoint, if it exists\n","if checkpoint_path:\n","    print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n","    model.load_weights(checkpoint_path, by_name=True)\n","else:\n","    print(\"No checkpoint found. Starting training from scratch.\")\n","\n","# Total number of epochs you want to train the model for\n","total_epochs = 2\n","\n","if initial_epoch < total_epochs:\n","    # Instantiate the custom callback\n","    metrics_callback = MetricsCallback()\n","\n","    # Resume training from the last saved checkpoint\n","    model.train(train_dataset=train_dataset, \n","                val_dataset=validation_dataset, \n","                learning_rate=disease_config.LEARNING_RATE, \n","                epochs=total_epochs,\n","                layers='heads',\n","                custom_callbacks=[metrics_callback])\n","else:\n","    print(f\"Training is already completed up to {total_epochs} epochs.\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Save the Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For testing, making the dataset smaller\n","#model_path = 'Disease_mask_rcnn_trained.h5'\n","model_path = '20-Disease_mask_rcnn_trained.h5'\n","model.keras_model.save_weights(model_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
